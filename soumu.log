2018-09-09 06:11:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: soumu_scrapy)
2018-09-09 06:11:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.4.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.0 (default, Sep  4 2018, 13:46:29) - [GCC 4.8.5 20150623 (Red Hat 4.8.5-28)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Linux-3.10.0-862.2.3.el7.x86_64-x86_64-with-centos-7.5.1804-Core
2018-09-09 06:11:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'soumu_scrapy', 'DOWNLOAD_DELAY': 1, 'FEED_FORMAT': 'json', 'FEED_URI': 'soumu.json', 'LOG_FILE': 'soumu.log', 'NEWSPIDER_MODULE': 'soumu_scrapy.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['soumu_scrapy.spiders']}
2018-09-09 06:11:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2018-09-09 06:11:29 [twisted] CRITICAL: Unhandled error in Deferred:
2018-09-09 06:11:29 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/vagrant/.pyenv/versions/3.6.0/lib/python3.6/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/home/vagrant/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scrapy/crawler.py", line 79, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/vagrant/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scrapy/crawler.py", line 102, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/vagrant/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 100, in from_crawler
    spider = super(CrawlSpider, cls).from_crawler(crawler, *args, **kwargs)
  File "/home/vagrant/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scrapy/spiders/__init__.py", line 51, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/vagrant/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 40, in __init__
    self._compile_rules()
  File "/home/vagrant/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 92, in _compile_rules
    self._rules = [copy.copy(r) for r in self.rules]
TypeError: 'Rule' object is not iterable
2018-09-09 06:13:53 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: soumu_scrapy)
2018-09-09 06:13:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.4.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.0 (default, Sep  4 2018, 13:46:29) - [GCC 4.8.5 20150623 (Red Hat 4.8.5-28)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Linux-3.10.0-862.2.3.el7.x86_64-x86_64-with-centos-7.5.1804-Core
2018-09-09 06:13:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'soumu_scrapy', 'DOWNLOAD_DELAY': 1, 'FEED_FORMAT': 'json', 'FEED_URI': 'soumu.json', 'LOG_FILE': 'soumu.log', 'NEWSPIDER_MODULE': 'soumu_scrapy.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['soumu_scrapy.spiders']}
2018-09-09 06:13:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2018-09-09 06:13:53 [twisted] CRITICAL: Unhandled error in Deferred:
2018-09-09 06:13:53 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/vagrant/.pyenv/versions/3.6.0/lib/python3.6/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/home/vagrant/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scrapy/crawler.py", line 79, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/vagrant/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scrapy/crawler.py", line 102, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/vagrant/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 100, in from_crawler
    spider = super(CrawlSpider, cls).from_crawler(crawler, *args, **kwargs)
  File "/home/vagrant/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scrapy/spiders/__init__.py", line 51, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/vagrant/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 40, in __init__
    self._compile_rules()
  File "/home/vagrant/.pyenv/versions/3.6.0/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 92, in _compile_rules
    self._rules = [copy.copy(r) for r in self.rules]
TypeError: 'Rule' object is not iterable
